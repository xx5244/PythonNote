# Requests套件
---

**第三方HTTP的套件，用`pip`即可安裝**
[官網](https://docs.python-requests.org/en/master/)

+ ## 模組請求常見參數
    | 參數名          | 意思                                       |
    | :-------------- | :----------------------------------------- |
    | method(必填)    | 請求方法                                   |
    | url(必填)       | 請求網址                                   |
    | headers         | 標頭檔(請求頭，字典型式)                   |
    | cookies         | 用戶身分訊息(cookiejar對象，字典型式)      |
    | params          | 查詢參數(字典型式)                         |
    | data            | post請求時傳送資料用(字典、列表、元組型式) |
    | verify          | 是否驗證證書(ca證書，SSL憑證)              |
    | timeout         | 設定響應時間，超過時間會報錯               |
    | allow_redirects | 是否允許重定向(布林型式)                   |
    | proxies         | ip代理                                     |



+ ## 請求參數範例
    ```python
    import requests

    ## method url
    # url = 'http://google.com/'
    # print(requests.get(url=url))


    ## headers
    # url = 'http://google.com/'
    # headers = {
    #     'referer': 'https://www.google.com',
    #     'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
    #     }
    # print(requests.get(url=url, headers=headers))


    ## cookies
    # url = 'https://www.google.com.tw/search'
    # headers = {
    #     'referer': 'https://www.google.com',
    #     'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
    # }

    # 每段分開型式
    # cookies = {
    #     'HSID': 'ArhgUbAh-67FgJTu3',
    #     'SSID': 'Akpi0XQQaPrwMjF9G',
    #     'APISID': 'CQiWP7y33F6COrja/ANnXFl8Gg1PLGjiBt',
    #     'SAPISID': 'pSf83eGQGswh6eM7/A0qE19KsN_bnwHFQX',
    #     '__Secure-3PAPISID': 'pSf83eGQGswh6eM7/A0qE19KsN_bnwHFQX',
    #     'ANID': 'AHWqTUnXKpKnpwNF_3p4JcpQZoy3lnjoptkHUtuuRpOjFTsgsoXXu14bxM1pUK5t',
    #     'SEARCH_SAMESITE': 'CgQI1pIB',
    #     'SID': 'AQjfU8v2onxAxJqTGnwwue_awzdzdEzDLYOPbGNZ_AWX80BA_LcWcOLL_-XEUt_2zGZaZw.',
    #     '__Secure-3PSID': 'AQjfU8v2onxAxJqTGnwwue_awzdzdEzDLYOPbGNZ_AWX80BAYRil6R8HjoE6Rj_YubV_uQ.',
    #     '1P_JAR': '2021-08-02-12',
    #     'DV': '0-g1ej7T4ZFIECBuCtWvdH2XO35usFf4WvFgpuJ_WgEAAFBxZ8UCkzF_fwAAALgHGACE7GREQQAAAA',
    #     'NID': '220=X1kvnWhZqqr6VhEqQvaPqujm3DjC6w964nFukMfcUe5wQDyhXktoWrZ1H9GP4HyXHbnEHRgfAc21efI5BA2YoP4hMZixD0U8F8PcdJhqXXRoX1Mr2vVS7OcVYD15DgclwKpd0u5d7LtdqmiDiaFGnFUSzSSVMqhKZuQpndTzO9ro6GbxJQt3STLinfV1DkkSBTDilGFgzkD6ueuzhHgVYak58UO1ONY9B9_teKEyUqEpYb3tOadv-ONYkZgbXE6gBmtUgme-Cqugj9CTdxmh08tdHavcPhWZpQDPPfSW',
    #     'UULE': 'a+cm9sZTogMQpwcm9kdWNlcjogMTIKdGltZXN0YW1wOiAxNjI3OTA4ODExMTk1MDAwCmxhdGxuZyB7CiAgbGF0aXR1ZGVfZTc6IDI1MDQ2MTAwMAogIGxvbmdpdHVkZV9lNzogMTIxNjEzNjg5Mwp9CnJhZGl1czogMTczNjAKcHJvdmVuYW5jZTogNgo'
    # }

    # 直接複製型式
    # cookies = {
    #     'cookies': 'HSID=ArhgUbAh-67FgJTu3; SSID=Akpi0XQQaPrwMjF9G; APISID=CQiWP7y33F6COrja/ANnXFl8Gg1PLGjiBt; SAPISID=pSf83eGQGswh6eM7/A0qE19KsN_bnwHFQX; __Secure-3PAPISID=pSf83eGQGswh6eM7/A0qE19KsN_bnwHFQX; ANID=AHWqTUnXKpKnpwNF_3p4JcpQZoy3lnjoptkHUtuuRpOjFTsgsoXXu14bxM1pUK5t; SEARCH_SAMESITE=CgQI1pIB; SID=AQjfU8v2onxAxJqTGnwwue_awzdzdEzDLYOPbGNZ_AWX80BA_LcWcOLL_-XEUt_2zGZaZw.; __Secure-3PSID=AQjfU8v2onxAxJqTGnwwue_awzdzdEzDLYOPbGNZ_AWX80BAYRil6R8HjoE6Rj_YubV_uQ.; 1P_JAR=2021-08-02-12; DV=0-g1ej7T4ZFIECBuCtWvdH2XO35usFf4WvFgpuJ_WgEAAFBxZ8UCkzF_fwAAALgHGACE7GREQQAAAA; NID=220=X1kvnWhZqqr6VhEqQvaPqujm3DjC6w964nFukMfcUe5wQDyhXktoWrZ1H9GP4HyXHbnEHRgfAc21efI5BA2YoP4hMZixD0U8F8PcdJhqXXRoX1Mr2vVS7OcVYD15DgclwKpd0u5d7LtdqmiDiaFGnFUSzSSVMqhKZuQpndTzO9ro6GbxJQt3STLinfV1DkkSBTDilGFgzkD6ueuzhHgVYak58UO1ONY9B9_teKEyUqEpYb3tOadv-ONYkZgbXE6gBmtUgme-Cqugj9CTdxmh08tdHavcPhWZpQDPPfSW; UULE=a+cm9sZTogMQpwcm9kdWNlcjogMTIKdGltZXN0YW1wOiAxNjI3OTA4ODExMTk1MDAwCmxhdGxuZyB7CiAgbGF0aXR1ZGVfZTc6IDI1MDQ2MTAwMAogIGxvbmdpdHVkZV9lNzogMTIxNjEzNjg5Mwp9CnJhZGl1czogMTczNjAKcHJvdmVuYW5jZTogNgo='
    # }
    # response = requests.get(url=url, headers=headers, cookies=cookies)
    # print(response)  # 查看狀態碼


    ## params
    # url = 'https://www.google.com.tw/search'
    # headers = {
    #     'referer': 'https://www.google.com',
    #     'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
    #     }
    # params = {
    #     'q': 'python requests'
    # }
    # response = requests.get(url=url, headers=headers, params=params)
    # print(response) # 查看狀態碼
    # print(response.url) # 查看網址

    # params['q'] = '中文測試'
    # response = requests.get(url=url, headers=headers, params=params)
    # print(response.url) # 查看網址


    ## data
    # url = 'https://www.thsrc.com.tw/TimeTable/Search'
    # headers = {
    #     'origin': 'https://www.thsrc.com.tw',
    #     'referer': 'https://www.thsrc.com.tw/ArticleContent/a3b630bb-1066-4352-a1ef-58c7b4e8ef7c',
    #     'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
    # }
    # data = {
    #     'SearchType': 'S',
    #     'Lang': 'TW',
    #     'StartStation': 'NanGang',
    #     'EndStation': 'ZuoYing',
    #     'OutWardSearchDate': '2021/08/02',
    #     'OutWardSearchTime': '17:00',
    #     'ReturnSearchDate': '2021/08/02',
    #     'ReturnSearchTime': '17:00'
    # }

    # response = requests.post(url=url, headers=headers, data=data)
    # print(response)


    ## verify
    # url = 'http://google.com/'
    # print(requests.get(url=url, verify=False))


    ## timeout
    # url = 'https://github.com/'
    # requests.get(url=url, timeout=0.001)


    ## allow_redirects
    # url = 'http://github.com/'
    # response = requests.get(url=url)
    # print(response.status_code)
    # print(response.history)
    # response = requests.get(url=url, allow_redirects=False)
    # print(response.status_code)
    # print(response.history)


    ## proxies
    # url = 'http://example.org'
    # proxies = {
    #   'http': 'http://10.10.1.10:3128',
    #   'https': 'http://10.10.1.10:1080',
    # }

    # print(requests.get(url=url, proxies=proxies))


    '''
    method 必填 為請求方法(get, post, ...etc)
    url 必填，為請求網址
    headers 設定標頭擋
    cookies 設定身分認證訊息，每段用分號隔開，基本上是key=value的形式，有些片段是瀏覽器自動生成的，
    有些則是伺服器回應時才生成的，很多時候伺服器回應時才生成的都是已經過身分認證後才決定要給的
    params 設定查詢參數(會出現在url裡)
    由於url不支援中文，因此會把中文轉成url編碼格式
    data 設定post發送請求時夾帶的參數，在chrome Headers底下可以看到Form Data來查看傳遞的參數
    verify 為數位證書(TLS憑證亦即SSL憑證)，默認是會驗證的，若該網站沒SSL憑證可能會出現報錯
    ca證書其實就是TLS憑證/SSL憑證，因為該憑證是由ca這個組織所發佈的
    timeout 設定限制時間，若伺服器回應時間超過限制時間則會報錯(requests.exceptions.ConnectTimeout)，可以用錯誤處理解決
    allow_redirects 是否允許網站重定向
    proxies ip代理
    '''
    ```


+ ## 模組響應常見參數
    | 參數名          | 意思                                       |
    | :-------------- | :----------------------------------------- |
    | url       | 查看伺服器返回的網址 |
    | status_code     | 查看狀態碼                                 |
    | history         | 查看伺服器返回對象的歷史                    |
    | encoding      | 查看網站編碼 |
    | apparent_encoding | 自動辨識網站編碼 |
    | cookies | 查看伺服器返回的cookies數據 |
    | headers         | 查看伺服器返回的headers數據 |
    | text   | 獲取返回的文本數據(字串型式)|
    | content| 獲取二進制數據(二進制型式)|
    | json()            | 獲取json數據(字典型式)                  |


+ ## 響應參數範例
    ```python
    import requests

    ## url
    # url = 'http://github.com/'
    # response = requests.get(url=url)
    # print(response.url)


    ## status_code
    # url = 'https://github.com/'
    # response = requests.get(url=url)
    # print(response.status_code)


    ## history
    # url = 'https://github.com/'
    # response = requests.get(url=url)
    # print(response.history)


    ## encoding
    # url = 'https://www.xbiquge.la/10/10489/4534454.html'
    # response = requests.get(url=url)
    # print(response.encoding)


    ## apparent_encoding
    # url = 'https://www.xbiquge.la/10/10489/4534454.html'
    # response = requests.get(url=url)
    # print(response.apparent_encoding)


    ## cookies
    # url = 'https://github.com/'
    # response = requests.get(url=url)
    # print(response.cookies)


    ## headers
    # url = 'https://github.com/'
    # response = requests.get(url=url)
    # print(response.headers)


    ## text
    # url = 'https://github.com/'
    # response = requests.get(url=url)
    # print(response.text)


    ## content
    # url = 'https://www.google.com.tw/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png'
    # response = requests.get(url=url)
    # print(response.content)


    ## json()
    # url = 'https://api.github.com/'
    # response = requests.get(url=url)
    # print(response.json())


    '''
    url 查看伺服器返回的網址，注意:返回的網址不一定等於你送出去的網址，因為有可能網址被重新導向至新的網址
    status_code 查看伺服器回應的狀態碼
    history 查看完成請求而創建的Response對象，該列表按從最早到最近的響應排序
    encoding 從header中的查看網站編碼
    apparent_encoding 自動辨識網站編碼
    與encoding的差異在於，encoding是從Header中content-type的charset字段中提取的編碼方式，若沒有charset字段則默認為ISO-8859-1編碼模式，中文的話就會是亂碼
    只要把response.encoding指定編碼或者直接設定成response.apparent_encoding即可解決
    response 查看伺服器返回的cookies，得到的是RequestsCoolieJar物件
    headers 查看伺服器返回的標頭檔
    text 獲取伺服器返回的文本數據
    content 獲取伺服器返回的二進制數據
    json() 獲取伺服器返回的json數據並轉換成字典，資料型態是字典，
    如果網站必非json數據而用此指令讀的話會發生錯誤(JSONDecodeError)
    '''
    ```