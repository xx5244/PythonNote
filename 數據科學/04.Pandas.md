# Pandas
---

+ ## 結構化數據分析利器(依賴Numpy)
+ ## 提供多種高級數據結構
    1. Time-Series
    2. DataFrame
    3. Panel
+ ## 強大數據索引和處理能力

+ ## Series
  + ### 說明
    **Pandas套件底下的方法，一維維度的表格，以list為基底**
  + ### 範例
    ```python
    import numpy as np
    import pandas as pd

    a = [1, 2, 3, 4]

    # 創建一個空白的Series
    # s = pd.Series([], dtype=pd.StringDtype()) # 宣告空白的Series要給定資料型態，不然會出現警告

    # 創建一個Series
    # s = pd.Series(a)
    # print(s)  # 印出內容
    # print(s.index)    # 印出索引
    # print(s.values)   # 印出值
    # print("索引1的值:", s[1]) # 索引方式印出值
    # print("最大值:", s.max())
    # print("最小值:", s.min())
    # print("中位數:", s.median())
    # print("資料放大兩倍:", s * 2, sep="\n")

    # 篩選資料
    # condition = s > 2
    # print("內容值大於2的內容:", s[condition], sep="\n")


    # 自定義index
    # s1 = Series(a, index=['A', 'B', 'C', 'D'])
    # print(s1)

    # 透過numpy的array創建Series
    # s2 = Series(np.arange(5))
    # print(s2)

    # 透過字典創建Series
    # d = {
    #     'A': 1,
    #     'B': 2,
    #     'C': 3,
    #     'D': 4
    # }
    # s3 = pd.Series(d)
    # print(s3)
    # print(s3.index)
    # print(s3.values)

    # 將Series轉換成字典
    # d2 = s3.to_dict()
    # print(d2)

    # 將Series布林值全部反轉
    # old = pd.Series([True, True, True, False, False])
    # print(old)
    # print('分隔線')
    # new = ~old
    # print(new)    

    """
    注意: 創建空白的Series時，最好先給定資料型態，不然之後可能會有警告出現
    index會默認自動創建，也可以指定
    用字典創建的Series，字典中的key會變成index，而value就會變成value
    將Series轉成字典的話，就是index轉乘key，value轉成value
    """
    ```

+ ## DataFrame
  + ### 說明
    **Pandas套件底下的方法，二維維度的表格，以dict為基底**
  
  + ### 常用功能
    1. **製作資料**
       + #### 範例
          ```python
          import pandas as pd

          a = [1, 2, 3, 4]

          # 創建一個DataFrame
          # ind = ['a', 'b', 'c']
          # data_dict = {
          #     'name': ['Amy', 'John', 'David'],
          #     'salary': [3000, 5000, 8000],
          #     'heigh': [180, 190, 230]
          # }

          # data = pd.DataFrame(data_dict)
          # data2 = pd.DataFrame(data_dict, index=ind)  # 指定index

          # print(data)
          # print(f'{"="*30}')
          # print(data2)

          # 若字典中的value非容器的話需寫入index
          # data_dict = {
          #     'name': 'Amy',
          #     'salary': 3000,
          #     'heigh': 180
          # }

          # data = pd.DataFrame(data_dict, index=[0])
          # print(data)

          """
          這邊要注意的是，若字典中的value值為單一值，而非容器的話，在創建的時候需多傳入一個index值，不然會發生錯誤訊息如下
          ValueError: If using all scalar values, you must pass an index
          """

          # 改變index
          ind = ['a', 'b', 'c']
          data_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [3000, 5000, 8000],
              'heigh': [180, 190, 230]
          }

          # data = pd.DataFrame(data_dict)
          # data = data.set_index('name')   # 用name欄位來當index
          # data = data.set_index(['name', 'salary'])   # 用name欄位與salary來當index
          # s = pd.Series([2, 1, 3])
          # data = data.set_index([s, s**2])    # 用自創的Series來當index

          # data = data.set_index(s)
          # data = data.reset_index()   # reset index
          # print(data)

          """
          set_index: 設定index，可由原本就有的欄位來當index
          reset_index: 重置index，會先原本的index變成一個新的欄位處理
          """ 
          ```

    2. **儲存資料**
       + #### 範例
          ```python
          import pandas as pd

          # 創建一個DataFrame
          data_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [3000, 5000, 8000],
              'heigh': [180, 190, 230]
          }

          data = pd.DataFrame(data_dict)
          data.to_csv('test.csv', encoding='utf-8', index=None)   # 輸出成csv檔
          """
          to_csv: 輸出成csv檔，當然也可以輸出成別的檔案類型，編碼建議用utf-8，index預設是有的，如果不要就要設定為None
          """       
          ```

    3. **讀取資料**
       + #### 範例
          ```python
          import pandas as pd

          data = pd.read_csv('test.csv', header=None) # 讀取csv檔
          print(data)

          """
          read_csv: 讀取csv檔變成DataFrame形式，header為是否把第一列當作是屬性，預設為是，如不要就要設定為None

          關於UnicodeDecodeError
          如果用mac系統沒特別設置編碼的話，很可能用win系統讀出時會出現UnicodeDecodeError錯誤訊息，此時要將讀取的encoding從'utf-8'改成'cp1252'
          
          關於DtypeWarning
          如果讀取的資料中，欄位裡的資料型態並不一致，會造成出現此錯誤，解決方法有2
          法1. 使用low_memory
          此方法會自行判斷數據類型，並給予明確的資料型態，缺點是很佔內存

          法2. 使用dtype
          此方法是直接給定資料型態，可以一次全部欄位指定資料型態亦或針對個別的欄位做給予資料型態的動作，個別做是用字典方式達成
          例:data = pd.read_csv('test.csv', dtype={'id': int})
          """          
          ```

    4. **查詢與篩選資料**
       + #### 範例
          ```python
          import pandas as pd
          import numpy as np       

          # 創建資料
          data_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [3000, 5000, 8000],
              'heigh': [180, 190, 230]
          }

          data = pd.DataFrame(data_dict)  # 不指定index
          # data = pd.DataFrame(data_dict, index=['a', 'b', 'c']) # 指定index
          
          # 查看row
          # print(data.head(num)) # 顯示前num row的資訊，不填預設為5
          # print(data.tail(num)) # 顯示後num row的資訊，不填預設為5

          # 查看column
          # print(data.columns) # 查看columns

          # 查看訊息
          # print(data.info())
          """
          pandas裡面string類型會寫成object類型
          當中的memory usage只是預估佔用的記憶體容量，實際上不會真正去看記憶體用了多少，預估最少佔用多少而已，所以才會有個+號
          如要查詢記憶體真正佔用多少容量可多加參數來查看memory_usage='deep'
          例:print(data.info(memory_usage='deep'))
          """

          # 查看index
          # print(data.index)

          # 查看資料型態
          # print(data.dtypes)

          # 取row的內容
          # print(data[0:3])  # 直觀好用
          # print(data.loc[['a', 'c']])   # 指定index，將想要row的index一一輸入
          # print(data.loc['a':'b'])   # 指定index，文字類也能用區間
          # print(data.loc[0:2])  # 不指定index也可用區間
          # print(data.iloc[0:2])  
          # print(data[[True, False, True]])  # 此型態經常搭配篩選條件使用

          # 讀取column內容
          # print(data['name'])
          # print(data.name)  # 不建議使用此方法
          # print(data.iloc[:, 0])

          # 讀取多column內容
          # print(data[['name', 'heigh']])
          # print(pd.DataFrame(data, columns=['name', 'heigh']))

          # 讀取多column內容 - 進階
          # data['new'] = [928, 384, 947] # 新增欄位測試效果
          # print(pd.Series(data.columns)) # 印出columns對應位置
          # print(data.iloc[:, np.r_[0:2, 3]]) # 印出name、salary及new欄位的值

          # 讀取row及column綜合運用
          # print(data.loc[0:2, ['name', 'salary']])
          # print(data.iloc[0:3, 0:2])

          # 查詢資料
          # print(data.isin([5000, 'Amy'])) # 找出DataFrame裡是否有值為5000或者'Amy'的
          # print(data['name'].isin(['Amy']))   # 找出name欄位裡有沒有叫'Amy'的

          # 篩選資料
          # condition = data['salary'] > 4000
          # print(data[condition])

          # 篩選資料搭配判別式
          # condition1 = data['salary'] > 3500 # 薪水大於3500
          # condition2 = data['heigh'] > 200    # 身高大於200
          # if condition1.bool and condition2.bool: # 如果兩個條件都符合
          #     print(data[condition1][condition2]) # 把結果印出來          
          
          # 比對兩個DataFrame中重複的資料
          # data1 = {
          #     'name': ['林心如', '黃慈敏', '糖兒'],
          #     'heigh': [160, 158, 178]
          # }

          # data2 = {
          #     'name': ['寶貝', '心茹', '黃慈敏', 'Linda'],
          #     'cup': ['C', 'E', 'C', 'A']
          # }

          # data1 = pd.DataFrame(data1)
          # data2 = pd.DataFrame(data2)

          # print(pd.merge(data1, data2, left_on='name', right_on='name', how='inner'))

          # 比對兩個DataFrame中相異的資料
          # result = pd.merge(data1, data2, left_on='name', right_on='name', how='outer', indicator=True)
          # print(result.loc[lambda x : x['_merge'] != 'both'])
          
          # 建議不要用chained indexing，詳細可參考淺談SettingWithCopyWarning
            import pandas as pd

            data = {
                "auctionid": ["8213034705", "8213034705", "8213034705", "8213034705", "8213060420"],
                "bidder": ["jake7870", "davidbresler2", "gladimacowgirl", "daysrus", "donnie4814"],
                "bidderrate": [0, 1, 58, 10, 5],
                "price": [110.8, 424, 553, 10, 553],
            }
            data = pd.DataFrame(data)

            # case 1
            # data[data["bidder"] == "davidbresler2"]["bidderrate"] = 100
            # print(data)

            # case 1 解法
            # data.loc[data["bidder"] == "davidbresler2", "bidderrate"] = 100
            # print(data)


            # case 2
            # temp = data.loc[data["bidderrate"] == data["price"]]
            # temp.loc[3, "bidder"] = "therealname"
            # print(temp)

            # case 2 解法
            # temp = data.loc[data["bidderrate"] == data["price"]].copy()
            # temp.loc[3, "bidder"] = "therealname"
            # print(temp)


            # 利用正則表達式來篩選資料
            # 將欄位中的BH後面的值給取出來，並放到新增名為new的欄位裡
            import pandas as pd
            import re

            data = pd.DataFrame(
                {"OBJ_DESC": ["BH163.9cm(75-90)", "BH: 16cm(>97) 0.9cm/2m 110.3.4"]}
            )

            # 寫正則表達式取出BH後面的值
            pat = "(?:Bh:?\s?)(\d{2,3}\.?\d{0,1})"

            # 利用findall來實踐
            BH = data["OBJ_DESC"].str.findall(pat, flags=re.I)
            data["new"] = BH.str[0]  # 由於上列執行完回傳值是list，先將其轉為str，再將其值取出
            print(data)
          """
          讀取row內容有四種方法
          法1. 讀取位置的，用區間的方式表示欲讀取的row的位置，
          法2. 讀取標籤(label)的，loc，輸入欲讀取的row的標籤
          法3. 讀取位置(position)的，iloc，同法1
          法4. 傳入bool值，來給定是否讀取該row內容

          loc主要是根據index的標籤名來運作的，因此只要把標籤名改掉，loc內的值也要相對應改掉
          iloc主要是根據索引的位置來運作的，因此，即使把標籤名改掉，iloc內的值也不需要對應改掉

          如果用loc讀取僅一個row的話，顯示方式會不同，兩個以上就會是DataFrame的型式
          用loc，注意:如果沒指定index的話，那預設就是從0開始，這種情況下也能使用區間的模式，由於是用標籤來運作，所以區間的話前後是都有算的

          如果用iloc讀取僅一個row的話，顯示方式會不同，兩個以上就會是DataFrame的型式
          用iloc是取位置的，所以區間的話最後的數值都是不包含的

          讀取column內容有三種方法
          法1. 讀取欄位名，data['欄位名']；讀多欄位的話就是要變成list格式data[['欄位名1', '欄位名2']]
          法2. 讀取欄位名，data.'欄位名' - 此方法不建議使用，因為欄位名要是有空格就無法用了
          法3. 讀取位置，iloc[:, column的位置]，這邊是預設全部的row都要取

          iloc是取位置的，[row, column]內分兩個部分，row為row的位置，column為column的位置

          總結:
          df[]
          裡面為數字則為取row內容(若index為預設的話)
          若要取多個row內容可用數字+區間，但僅能用區間，不能單獨多個
          裡面為bool則取row內容
          若要取多個row內容可用[]方式將多bool放進去
          裡面為文字則為欄位名取columns內容
          若要取多個column內容可用[]方式將多欄位名放進去
          讀取多區段columns可以用np.r_來達到效果

          loc
          可取出row與column的內容，判別方式row是依照index，而column是依照欄位名，其中row區塊可用[]方式放多個要取的row，column亦同
          df.loc[row, column]

          iloc
          基本上方法與loc同，只是判別方式皆是依照position

          查詢資料
          用isin指令，傳回來的是布林值

          篩選資料
          利用讀取row、column、isin及運算符號來製作篩選條件，然後利用[]來篩選資料

          篩選資料搭配判別式
          由於直接用運算子做運算後的boolean的資料型態是pandas.core.series.Series的，而非一般的boolean，所以直接丟進if來使用會發生問題，因此，需搭配以下指令來進行處理
          DataFrame.bool()
          : bool是用來轉換成一般boolean用的指令，這樣就可搭配if來進行操作

          比對兩個DataFrame中重複及相異的資料
          merge: 依照指定欄位值來合併
          left_on: 左邊df要依照合併的欄位名
          right_on: 右邊df要依照合併的欄位名
          on: 兩邊都有的欄位名
          how: 決定是否完全合併，因為要是當兩個的row數不匹配時，可能結果不是想要的，將此參數給定inner的話，就會取得兩資料間的交集，也就是相同之處，而outer的話為聯集
          indicator: 是否顯示比較的結果，結果有3種
           1. left_only
           2. right_only
           3. both
          主要搭配取出相異的資料

          關於SettingWithCopyWarning
          當用Chained indexing來修改值的時候，會產生這個警告

          問題1.
          簡單的說鏈式的會一個一個獨立操作
          1.data[data["bidder"] == "davidbresler2"] # 這個會return一個新的Dataframe
          2.['bidderrate'] = 100 # 而這個賦值的操作會是作用在新的DataFrame上，而不是原本的DataFrame
          因此，會讓原有的DataFrame的值沒被修改到

          解決方法
          運用loc來將chained變成單個的操作

          問題2.
          隱藏起來的鏈式
          關於temp是用get的值創建出來的，data.loc[data.bid == data.price])可能是原始的，也可能不是
          因此，一樣有可能沒修改到原始的資料

          解決方法
          利用copy直接把值複製新的

          結論:這種給值最好就是copy搭配loc[condition]的方式，比較能確保是真實改到值

          利用正則表達式來取得資料
          findall就跟re裡面的findall差不多意思，只是Pandas裡的可以直接幫你批次處理，更是方便快速
          : pat: 正則表達式的規則
          : flags: 正則表達式的匹配模式，這邊的re.I指得是忽略大小寫
          由於findall回傳的長度會跟原data的row長度一樣，沒找到的部分會補NaN，因此，可以不用先行創建新的空白欄位          
          """          
          ```

    5. **替換資料**
       + #### 範例
          ```python
          import pandas as pd

          # 創建資料
          data_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [3000, 5000, 8000],
              'heigh': [180, 190, 230]
          }

          data = pd.DataFrame(data_dict)  # 不指定index

          # 一對一替換
          # data.replace('Amy', 'Linda', inplace=True)
          # print(data)

          # 多對一替換
          # data.replace(['Amy', 'John'], 'Linda', inplace=True)
          # print(data)

          # 多對多替換
          # data.replace({'Amy': 'Linda', 3000: 6000}, inplace=True)
          # print(data)

          # 去除空白
          # data.replace('\s+', '', regex=True, inplace=True)   # 去除空白

          # 修改欄位名
          # data = data.rename(columns={"name":"boss_name"})
          # print(data)         

          # 修改索引
          # data.rename(index={'name': 'new_name'}, inplace=True)

          """
          主要是用replace指令來替換，當中的inplace參數是指是否對原表直接做修改，預設為False
          多對多替換是用類似字典的型式

          loc[row,column]，row即是放condition返回的布林值，column即放column名稱

          注意:使用chained indexing的時候，索引操作的順序和類型部分決定了結果是原始對象的切片還是切片的副本，容易導致出來結果不如預期，因此，盡量避免

          修改欄位名
          df = df.rename(columns={"OldName":"NewName"})

          修改索引
          df = df.rename(index={"OldName":"NewName"})
          也可直接用欄位名代替
          """          

          # map函數替換
          data = pd.DataFrame({
              'name': ['Amy', 'John', 'David'],
              'sex': ['Female', 'Male', 'Male']    
          })  # 不指定index
          print(data)          
          data['sex'] = data['sex'].map({'Female': 0, 'Male': 1})
          print(data)
          data['name'] = data['name'].map({'Amy': 'Linda'})
          print(data)

          """
          map跟replace一樣可以替換，替換格式是用dict的格式，也要注意map是Series才有的屬性，DataFrame並沒有
          另外，map是找全Series中全部的值出來照dict來替換，如果dict沒有對應值，則回傳就會是NaN，跟replace只替換的，沒有的就不動是不一樣的
          """
          ```

    6. **新增資料**
       + #### 範例
          ```python
          import pandas as pd

          # 創建資料
          data_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [3000, 5000, 8000],
              'heigh': [180, 190, 230]
          }

          data = pd.DataFrame(data_dict)  # 不指定index

          # 新增row
          # 法1
          # data.loc[3] = ['tester', 1000000, 199]
          # data.loc[len(data)] = ['tester', 1000000, 199]
          # print(data)

          # 法2
          # data = data.append({'name': 'Linda', 'salary': 9000, 'heigh': 160}, ignore_index=True)
          # print(data)

          # 新增column
          # 法1
          # data['new'] = [100, 300, 800]
          # print(data)

          # 法2
          # data['new'] = pd.Series([100, 300])
          # print(data)

          # 插入
          # data.insert(1, 'weight', [100, 300, 800], allow_duplicates=True)
          # print(data)

          # 插入row
          import numpy as np
          print(data)
          new_row = ['Anna', 13000, 168]
          data = pd.DataFrame(np.insert(data.values, 1, new_row, axis=0), columns=data.columns)
          print(data)

          """
          新增row的兩種方法
          法1. df.loc[index名] = 值，index名可數字可文字，給予的值需符合column的長度，可搭配len來直接給予index名
          法2. 利用append，然後配合字典型式傳入想新增的資料，ignore_index是表示是否用各自原來的index label，預設為False(不會生成新索引)

          新增column有兩種方法
          法1. 直接輸入欲新增的欄位名，給予的值需符合row的長度
          法2. 輸入欲新增的欄位名搭配Series給予值，給予的值不需符合row的長度，少的部分會是NaN值，注意: 如果有NaN值，那其它為數字的話，資料型態會是float64

          插入的方法基本上只有插入column的部分，使用insert指令
          df.insert(欲插入的位置, 欲插入的欄位名, 欲插入的值, allow_duplicates=True)
          給予的值需符合row的長度，allow_duplicates預設為False，此為是否允許插入同樣欄位名
          
          如果要插入row的話，就要借用到numpy的insert指令了
          np.insert(原始的值, 欲插入的index, 欲插入的值, axis=0)
          別忘了後面還要把新建立的columns與原columns做賦值的動作
          """          
          ```

    7. **刪除資料**
       + #### 範例
          ```python
          import pandas as pd

          # 創建資料
          data_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [3000, 5000, 8000],
              'heigh': [180, 190, 230]
          }

          data = pd.DataFrame(data_dict)  # 不指定index

          # data.drop(index=[1, 2], inplace=True, axis=False)
          # data.drop(columns=['name', 'salary'], inplace=True, axis=True)

          # data = data.iloc[:-1] # 刪除最後一個row

          """
          基本上就是用drop指令
          : inplace是表示是否直接修改，預設為False
          : axis True為對column動作，False為對row動作，預設False
          : index是標籤名不是位置，不一定要此參數，會根據axis指定來判斷要對row還column作動
          : column是欄位名，不一定要此參數，會根據axis指定來判斷要對row還column作動

          使用取值的方式把想要的值取出來似乎比較快，用計時上看是這樣
          """          
          ```

    8. **處理缺失值**
       + #### 範例
          ```python
          import pandas as pd

          # 創建資料
          data_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [3000, 5000, 8000],
              'heigh': [180, None, 230]
          }

          data = pd.DataFrame(data_dict)  # 不指定index
          # condition = data.isna().any(axis=True) # 找尋缺失值，用any搭配
          # print(data[condition])  
          # print(data.dropna(how='all'))   # 刪除缺失值
          # print(data.fillna(0))
          # print(data.fillna({'heigh': 340}))

          """
          isna指令為檢查缺失值，可以搭配any或all指令做後續處理，回傳值為bool
          dropna指令為刪除缺失值的row
          : how參數值'any'或'all'，當為any時，只要row中有一個NaN即整個row刪除，而all則是要全部都為NaN才刪除
          fillna指令為將所有缺失值填充為指定的值，也可利用字典的型式來給定
          """          
          ```

    9.  **處理重覆值**
       + #### 範例
          ```python
          import pandas as pd

          # 創建資料
          data_dict = {
            'name': ['Amy', 'John', 'David'],
            'salary': [3000, 5000, 8000],
            'heigh': [180, 190, 230]
          }

          data = pd.DataFrame(data_dict)  # 不指定index
          for i in range(5):
              data.loc[len(data)] = ['Amy', 3000, 180]
            
          data.loc[len(data)] = ['Amy', 4000, 180]
          print('原本的資料\n')
          print(data, '\n')

          # condition = data.duplicated()
          # print(data[condition]) # 找尋重複的值，回傳值是bool

          # 找尋columns name的重覆值
          # data = data.T
          # data.columns = [0, 1, 2, 3, 4, 5, 1, 2, 8]
          # data.loc[:, data.columns.duplicated(keep=False)]

          # data = data.drop_duplicates()
          # print('刪除重複值後的結果\n')
          # print(data)

          # data = data.drop_duplicates(subset=['salary']) 
          # print('僅刪除salary欄位有重複值的結果\n')
          # print(data)

          # 取得為一值
          # print('名字有以下幾個\n')
          # print(data['name'].unique())

          """
          duplicated為用來找尋重複的row
          : param keep: 'first'、'last'、False，default='first'
          : param return: Series(bool)
          drop_duplicates為用來刪除重複的row
          : keep參數可以有3個值，'first'、'last'、False，預設為'first'
          : 'first'參數為保留第一個重複值剩下的刪除
          : 'last'參數為保留最後一個重複值剩下的刪除
          : False值為刪除所有的重複值
          : subset參數為column labels，僅看此欄位的值有無重複，不然預設是全部欄位值都一樣才算重複
          unique為用來獲取欄位中唯一值
          """                
          ```

    10. **排序資料**
       + #### 範例
          ```python
          import pandas as pd

          # 創建資料
          data_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [5000, 3000, 1000],
              'heigh': [980, 130, 190]
          }

          data = pd.DataFrame(data_dict)  # 不指定index

          # print(data.sort_values(by=['salary']))  # 根據salary欄位來作排序

          # print(data.sort_values(by=['heigh'], ascending=False))  # 根據salary欄位來作排降序

          # 雙欄位排序
          data = pd.DataFrame({
            'group': ['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c'],
            'data': [4, 3, 2, 1, 12, 3, 8, 9, 7]
          })

          print(data)
          data.sort_values(by=['group', 'data'], ascending=[False, True], inplace=True)   # 在group為降序排列後的前提下，data做升序排列
          print(data)

          # data.sort_index(inplace=True) # 根據index來進行排序

          """
          sort_values為排序值用的指令，基本上就是針對欄位作為排序
          : by參數為欲排序的欄位名
          : ascending參數為指定升降序，True為升序，False為降序，預設為True

          sort_index根據index來進行排序，在利用index值做操作時好用
          """          
          ```

    11. **合併資料**
       + #### 範例
          ```python
          import pandas as pd

          # 創建資料
          data1_dict = {
              'name': ['Amy', 'John', 'David'],
              'salary': [5000, 3000, 1000],
              'heigh': [980, 130, 190]
          }

          data2_dict = {
              'name': ['Linda', 'Emily'],
              'salary': [50000, 30000],
              'heigh': [150, 160]
          }


          data1 = pd.DataFrame(data1_dict)  # 不指定index
          data2 = pd.DataFrame(data2_dict)  # 不指定index

          # print(pd.concat([data1, data2], ignore_index=True))

          # print(data1.append(data2, ignore_index=True))
            
            # 資料根據某欄位來做合併
            A = {
                '番號': ['URKK-049', 'MKMP-430', 'MKMP-429', 'MDTM-750', 'MDTM-749', 'URKK-049'],
                '片名': ['test1', 'test2', 'test3', 'test4', 'test5', 'test']
            }

            A = pd.DataFrame(A)

            B = {
                '番號': ['URKK-049', 'MKMP-430', 'MKMP-429', 'MDTM-750', 'MDTM-749'],
                '長度': ['142分鐘', '145分鐘', '150分鐘', '120分鐘', '125分鐘']
            }

            B = pd.DataFrame(B)
            print(pd.merge(A, B, left_on='番號', right_on='番號', how='outer'))

          """
          合併有兩種方法
          法1.
          concat: 合併兩個DataFrame，axis為0(預設)是row合併，1則是column合併，注意:只能0或1不能True跟False喔，另外，如果index不同的話，column合併會是row+column合併喔
          : ignore_index參數為忽略index，預設為False，也就是預設為不忽略index，合併之後的index不會重新排列，會按照原本的
          : axis，如果為0則為row合併，1為column合併，預設為0
          法2.
          append: 用法跟新增row一樣

          根據欄位值合併
          merge: 依照指定欄位值來合併
          left_on: 左邊df要依照合併的欄位名
          right_on: 右邊df要依照合併的欄位名
          how: 決定是否完全合併，因為要是當兩個的row數不匹配時，可能結果不是想要的，將此參數給定outer的話，那缺失值會直接補NaN
          """          
          ```

    12. **對齊資料**
       + #### 範例
          ```python
          import pandas as pd

          # 創建資料
          data = {
              '收據編號': ['P02124179', 'P02124179', 'P02124183', 'P02124180', 'P02124087', 'P02125499', 'P02125307', 'P02125307', 'P02125256', 'P02125256', 'P02125259', 'P02125259'],
              '付款項目': ['規費', '服務費', '服務費', '服務費', '服務費', '服務費', '服務費', '規費', '服務費', '規費', '服務費', '規費'],
              '傳票號碼': ['J21100730045', 'J21100730046', 'J21100730046', 'J21100730047', 'J21100730048', 'F21100830001', 'F21100923001', 'F21100907009', 'F21101021001', 'F21101021002', 'F21101021003', 'F21101021004'],
              '預計付款日': ['2021/11/05', '2021/11/05', '2021/11/05', '2021/11/05', '2021/11/05', '2021/11/05', '2021/12/05', '2021/12/05', '2021/12/05', '2021/12/05', '2021/12/05', '2021/12/05'],
              '付款金額': [455, 1850, 700, 630, 700, 6000, 1000, 3341, 800, 350, 3150, 3787]
          }

          data = pd.DataFrame(data)
          pd.set_option('display.unicode.ambiguous_as_wide', True)    # 顯示對齊用
          pd.set_option('display.unicode.east_asian_width', True)     # 顯示對齊用
          print(data)          
          ```

    13. **any與all**
      + #### 範例
        ```python
        import pandas as pd

        # 創建資料
        data_dict = {
            'tt1': [True, True, True],
            'tt2': [False, False, False],
            'tt3': [False, False, True]
        }

        data = pd.DataFrame(data_dict)  # 不指定index
        print('原來資料\n')
        print(data)
        print(f'{"-" * 20}分隔線{"-" * 20}\n')
        print('使用any(column來看)\n')
        print(data.any())
        print(f'{"-" * 20}分隔線{"-" * 20}\n')
        print('使用all(column來看)\n')
        print(data.all())
        print(f'{"-" * 20}分隔線{"-" * 20}\n')
        print('使用any(row來看)\n')
        print(data.any(axis=1))
        print(f'{"-" * 20}分隔線{"-" * 20}\n')
        print('使用all(row來看)\n')
        print(data.all(axis=1))

        """
        any跟all都是用來對元素的真假做判斷的，可以是row也可以是column
        any是只要有一個元素為真即為真
        all是則需要全部元素為真才為真
        :param axis: {0 or 'index', 1 or 'columns', None},default 0
        """           
        ```

    14. **資料型態轉換**
      + #### 範例
        ```python
        import pandas as pd

        # 創建資料
        data_dict = {
            'name': ['Amy', 'John', 'David'],
            'salary': [5000, 3000, 1000],
            'heigh': [980, 130, 190]
        }

        data = pd.DataFrame(data_dict)

        print(data['salary'].to_numpy())
        print(data['salary'].tolist())
        print(data['salary'].to_string())
        print(data['salary'].to_dict())
        print(data['salary'].astype(str))
        print(data['name'].str.upper())
        print(data.loc[data['name'].isin(['John'])].squeeze())
        
        s = pd.Series(["a", "b", "c"],
              name="vals")
        print(s.to_frame()) 

        """
        to_numpy: 把欄位值變成numpy的格式
        tolist: 把欄位值變成list的格式
        to_string: 把欄位值變成str的格式
        to_dict: 把欄位值變成字典的格式，key值為index值，value則為欄位值
        astype: 把欄位內的資料型態統一轉換成想改的資料型態
        str: 字串方法中繼點，透過此方法之後，後面就能直接使用字串的方法了
        squeeze: 將DataFrame的資料型態轉為Series的資料型態
        to_frame: 將Series的資料型態轉為DataFrame的資料型態
        """        
        ```

    15. **時間操作**
      + #### 範例
        ```python
        import pandas as pd
        # 基本構造時間

        # 法1.
        # ts = pd.Timestamp('20220331')
        # add_day = pd.Timedelta(days=5)
        # print(ts)
        # print(ts.year)
        # print(ts.month)
        # print(ts.day)
        # print(ts + add_day)

        # 法2.
        # ts = pd.to_datetime('20220331')

        # 將Series轉換成時間戳
        # s = pd.Series(['20220404', '20220405', '20220406'])
        # ts= pd.to_datetime(s)
        # print(ts.dt.year)
        # print(ts.dt.month)
        # print(ts.dt.days)
        # print(ts.dt.weekday+1)
        # print(ts.dt.is_leap_year)

        """
        Timestamp: 時間戳，將文字轉換成時間格式
        Timedelta: 時間的差值，基本上最多就是以天為單位，往下可以時、分、秒
        時間格式可寫YYYYMMDD或者YYYY-MM-DD或DD/MM/YYYY
        構造時間有兩個方法
        法1. 用Timestamp
        法2. 用to_datetime
        dt.year: 顯示年
        dt.month: 顯示月
        dt.days: 顯示日
        dt.weekday: 顯示星期幾，這邊星期一會顯示0，星期日會顯示6，因此，建議+1去彌補，看得會比較習慣
        dt.is_leap_year: 判斷該年是否為閏年
        注意: 目前能使用的時間範圍是
        1677-09-21 00:12:43.145225 ~ 2262-04-11 23:47:16.854775807
        超過此時間段的話會報錯，當然，函數可能之後更新的時候會把時間往後延或怎樣的
        """

        # 構造時間序列
        # ts = pd.Series(pd.date_range(start='20220401', periods=10, freq='12H'))
        # print(ts)

        """
        date_range: 構造時間序列
        :start: 開始時間
        :end: 結束時間
        :periods: 要生成多少個時間
        :freq: 時間間隔頻率
        """

        # 實務操作
        # ts = pd.DataFrame({
        #     'date': pd.Series(pd.date_range(start='20220401', periods=10, freq='12D3H')),
        #     'tt': range(10)
        # })

        # ts = ts.set_index('date')   # 將時間作為索引以利後面操作
        # print(ts)
        # print(ts['2022-04': '2022-06'])   # 取某時間段的數據
        # print(ts[ts.index.month == 4])    # 取出某月份的資料
        # print(ts.between_time('03:00', '09:00'))    # 取出時間3點到9點的資料
        # print(ts.resample('14D9H').sum())   # 重新採樣，並進行和的計算
        """
        注意: 如果要娶某區間的數據，若不想給齊年月日的話，就只能用2022-04這種形式，並不能用202204這種形式
        """
        ```

    16. **常用數值運算**
      + #### 範例
        ```python
        import pandas as pd

        # 創建資料
        # data_dict = {
        #     'name': ['Amy', 'John', 'David'],
        #     'salary': [5000, 5000, 1000],
        #     'heigh': [980, 130, 190]
        # }

        # data = pd.DataFrame(data_dict)

        # print(data)

        # 求和
        # print("薪水總和:", data['salary'].sum())   # 預設按row求和
        # print(data.sum(axis=1))   # 按column求和

        # 求平均值  
        # print("薪水平均值:", data['salary'].mean())

        # 求最大值
        # print("薪水最大值:", data['salary'].max())

        # 求最小值
        # print("薪水最小值:", data['salary'].min())

        # 求中位數
        # print("薪水中位數:", data['salary'].median())

        # 計數數值個數
        # print('計數數值個數', data['salary'].count())

        # 唯一值
        # print(data['salary'].unique())

        # 統計數值出現的次數
        # print("數值出現次數:\n", data['salary'].value_counts())   # 預設降序
        # print("數值出現次數(升序):\n", data['salary'].value_counts(ascending=True)) # 升序
        # print("數值出現次數(分組):\n", data['salary'].value_counts(bins=1)) # 分組
        # print('計算比例:\n',  data['salary'].value_counts(normalize=True))
        # print('數值出現次數(包含None):\n', data['salary'].value_counts(dropna=False))

        # 二元統計
        # df = pd.DataFrame({
        #     "A":[5, 3, 6, 4],  
        #     "B":[11, 2, 4, 3], 
        #     "C":[4, 3, 8, 5], 
        #     "D":[5, 4, 2, 8]
        # }) 

        # print(df)
        # print('共變異數\n', df.cov()) # 協方差

        # print('相關係數\n', df.corr())  # 相關係數

        """
        sum: 總和值，也常用在計算篩選結果的個數
        mean: 的平均值
        max: 最大值
        min: 最小值
        median: 中位數
        :axis: 0為index(default)，1為columns
        count: 計數數值的個數
        unique: 唯一值，就是多少不同種的值
        value_counts: 統計值所出現的次數，回傳是降序的
        :param ascending: bool, default False(降序)
        :param bins: int，看數字多少就分幾組，統計會以組的方式來統計
        :param normalize: bool, default False，計算統計值的比例
        :param dropna: bool, default True，是否需要把None計算進去，False為要
        注意: value_counts基本上是針對Series的部分，所以即使把整個DataFrame丟進去也會是每個Column各自做統計，因此，想要統計整個DataFrame的話，可以先把DataFrame給變成一個Series，然後再做統計的動作
        注意: normalize計算的比例基本上是不包含None的，也就是說3筆資料如果一筆True，一筆False，一筆None，那直接用計算比例的話，由於不把None計算進去，那True跟False的比例都會是50%，如果想要連None計算進去的話，就要設定dropna=False

        cov: 共變異數(協方差)在機率論與統計學中用於衡量兩個隨機變數的聯合變化程度
        corr: 相關係數是一種相關程度的測量，在統計學上的意義是兩個變數之間的關係
        """  

        # 進階 - 統計整個DataFrame出現的個數
        ```

    17. **其餘常用功能**
      + #### 範例
        ```python
        import pandas as pd

        # 創建資料
        data_dict = {
            'name': ['Amy', 'John', 'David'],
            'salary': [5000, 3000, 1000],
            'heigh': [980, 130, 190]
        }

        data = pd.DataFrame(data_dict)

        # print("DataFrame的尺寸", data.shape)
        # print(pd.isna(data.loc[0, 'name']))
        # print(pd.notna(data.loc[0, 'name']))
        # print(data.empty)

        """
        shape: DataFrame的尺寸，m(row) * n(column)
        isna: 查看值是否為NaN
        notna: 查看值是否不為NaN
        empty: 判斷整個Dataframe是不是空的
        """    
        ```

    18. **深入merge**
      + #### 範例
        ```python
        import pandas as pd
        left = pd.DataFrame({
            'key': ['K0', 'K1', 'K2', 'K3'],
            'A': ['A0', 'A1', 'A2', 'A3'],
            'B': ['B0', 'B1', 'B2', 'B3']
        })
        right = pd.DataFrame({
            'key': ['K0', 'K1', 'K2', 'K3'],
            'C': ['C0', 'C1', 'C2', 'C3'],
            'D': ['D0', 'D1', 'D2', 'D3']
        })



        # 例1.最簡單的合併
        # print(left)
        # print(right)
        # result = pd.merge(left, right)
        # print(result)

        # 例2.多個column name重複的問題
        # right = right.drop(columns=['C'], axis=1)
        # right['A'] = ['A4', 'A1', 'A2', 'A4']
        # print(left)
        # print(right)
        # result = pd.merge(left, right)
        # print(result)

        # 例3.聯集
        # right = right.drop(columns=['C'], axis=1)
        # right['A'] = ['A4', 'A1', 'A2', 'A4']
        # print(left)
        # print(right)
        # result = pd.merge(left, right, on='key')
        # print(result)

        # 例4.左右長度不一做交集
        # right.drop(index=[1, 2], inplace=True, axis=False)
        # print(left)
        # print(right)
        # result = pd.merge(left, right)
        # print(result)

        # 例5.左右長度不一做交集(以較多row的那邊為主)
        # right.drop(index=[1, 2], inplace=True, axis=False)
        # print(left)
        # print(right)
        # result = pd.merge(left, right, how='left')
        # print(result)

        # 例6.左右長度不一做聯集
        # right.drop(index=[1, 2], inplace=True, axis=False)
        # print(left)
        # print(right)
        # result = pd.merge(left, right, how='outer')
        # print(result)

        # 例7.左右長度不一做聯集(以較少row的那邊為主)
        # right.drop(index=[1, 2], inplace=True, axis=False)
        # print(left)
        # print(right)
        # result = pd.merge(left, right, how='right')
        # print(result)

        # 例8.兩邊不同欄位名作交集
        # left = left.rename(columns={'key': 'key_left'})
        # right = right.rename(columns={'key': 'key_right'})
        # print(left)
        # print(right)
        # result = pd.merge(left, right, left_on='key_left', right_on='key_right')
        # print(result)

        # 例9.左邊的值有重複項做交集
        # left['key'].loc[1] = 'K0'
        # left['key'].loc[2] = 'K0'
        # print(left)
        # print(right)
        # result = pd.merge(left, right)
        # print(result)

        # 例10.左邊的值有重複項做聯集
        # left['key'].loc[1] = 'K0'
        # left['key'].loc[2] = 'K0'
        # print(left)
        # print(right)
        # result = pd.merge(left, right, how='outer')
        # print(result)

        # # 例11.兩邊都有重複的值做交集
        # left['key'].loc[1] = 'K0'
        # left['key'].loc[2] = 'K0'
        # right['key'].loc[1] = 'K0'
        # right['key'].loc[2] = 'K5'
        # print(left)
        # print(right)
        # result = pd.merge(left, right)
        # print(result)

        # 例12.兩邊都有重複的值做交集(右邊為主)
        # left['key'].loc[1] = 'K0'
        # left['key'].loc[2] = 'K0'
        # right['key'].loc[1] = 'K0'
        # right['key'].loc[2] = 'K5'
        # print(left)
        # print(right)
        # result = pd.merge(left, right, how='right')
        # print(result)

        """
        結論:使用merge時，要先觀察兩邊的檔案是否有重複性
        例1中可以看出，它會尋找共同的column name中相同值的row做合併，若兩邊相同的column name不只一個，那表示複數的column name都要有相同的值才會取出，如例2
        例3中可看出，左右都有相同的column name做聯集時，縱使有不同的值，還是可以合併，就是會多column另外命名處理
        例5中可看出，左邊的row比右邊多，做交集的話，設定以左邊為主，那缺失的部分會自動補NaN
        例6中可看出，左邊的row比右邊多，做聯集的話，會以最多row的為主，然後缺失部分會自動補NaN
        例7中可看出，以較少row的那邊為主的話，row數量就會是跟該側一樣
        例11中可看出，雙邊重複的話，資料量一定會暴增
        例12中可看出，雙邊重複的話，如果以左邊為主的話效果會跟例11相同，如果改以右邊為主，那right_only的部分則會補NaN值
        :param how: str，default=inner，決定要inner交集、outer聯集、left左邊為主、right右邊為主 
        :param indicator: bool，default=False，是否顯示merge的方法，基本上只有三種，both、left_only、right_only
        :param on: IndexLabel，欲根據兩邊都有的column name
        :param left_on: IndexLabel，欲根據左邊的column name
        :param right_on: IndexLabel，欲根據右邊的column name
        """        
        ```

    19. **將整個Df內所有元素滿足條件的整row變特定值**
      + #### 範例
        ```python
        import pandas as pd

        # 計數整個DataFrame所有元素出現的次數
        # left = pd.DataFrame({
        #     'key': ['K0', 'K1', 'B2', 'K3'],
        #     'A': ['A1', 'A1', 'A2', 'A1'],
        #     'B': ['B0', 'A1', 'B2', 'B3']
        # })

        # result = left.stack().value_counts()    # 計數整個DataFrame所有元素出現的次數
        # print(result)        

        """
        stack(): 將資料的列“旋轉”為行
        value_counts(): 計數次數
        """

        # 將index轉成column
        # left = pd.DataFrame({
        #     'key': ['K0', 'K1', 'B2', 'K3'],
        #     'A': ['A1', 'A1', 'A2', 'A1'],
        #     'B': ['B0', 'A1', 'B2', 'B3']
        # })

        # result = left.stack().value_counts()    # 計數整個DataFrame所有元素出現的次數
        # df = result.rename_axis('name').reset_index()   # 將index轉成column
        # print(df)   

        """
        rename_axis: 設置索引或列的軸名稱
        reset_index(): 重置index
        """

        # 從整個Df中找出特定值
        # left = pd.DataFrame({
        #     'key': ['K0', 'K1', 'B2', 'K3'],
        #     'A': ['A1', 'A1', 'A2', 'A0'],
        #     'B': ['B0', 'A1', 'B2', 'B3']
        # })

        # print(left)
        # print('分隔線')
        # print(left[left.isin(['B2', 'A1']).any(axis=1)])    # 找出DataFrame所有元素中，包含A1或B2的元素 

        # 將Df中，僅出現一次的元素，整row變為0
        # left = pd.DataFrame({
        #     'key': ['A1', 'K1', 'B2', 'K3'],
        #     'A': ['A1', 'A1', 'A2', 'A0'],
        #     'B': ['A1', 'A1', 'B2', 'B3']
        # })

        # result = left.stack().value_counts()    # 計數整個DataFrame所有元素出現的次數
        # df = result.rename_axis('name').reset_index()   # 將index轉成column
        # df = df.rename(columns={0: 'count'})    # 將column name修改一下
        # condition1 = df['count'] < 2 # 條件設定
        # condition2 = left.isin(list(df[condition1].name)).any(axis=1)    # 找出DataFrame所有元素中，包含condition內的元素   
        # left_new = left.copy()  # 複製以便比較
        # left_new[condition2] = left_new[condition2].replace(list(df.name), '0') # 從原Df找出符合條件的值，將其值變為'0'
        # print(df)
        # print('分隔線')
        # print(left)
        # print('分隔線')
        # print(left_new)
        ```

    20. **Groupby與Aggregate**
      + #### 範例
        ```python
        import pandas as pd

        data_dict = {
            'name': ['Amy', 'John', 'David'],
            'salary': [3000, 5000, 8000],
            'heigh': [180, 190, 230],
            'sex': ['Female', 'Male', 'Female']
        }

        data = pd.DataFrame(data_dict, index=['a', 'b', 'c'])  # 不指定index
        # print(data)

        # print(data.groupby('salary').count()) # 統計薪水在各columns中出現的次數
        # print(data.groupby(['salary', 'sex']).count()) # 統計薪水及性別在各columns中出現的次數
        # print(data.groupby('salary').groups) #查看組別
        # print(data.groupby('salary').get_group(5000)) # 尋找組別

        # 欲求男生總薪資與女性總薪資 - 一般方法
        # for i in ['Male', 'Female']:
        #     print(i, data.loc[data['sex'] == i, 'salary'].sum())

        # 欲求男生總薪資與女性總薪資 - 使用groupby
        # print(data.groupby('sex')['salary'].sum())

        # def test(x):
        #     print(type(x))
        # 欲求男生總薪資與女性總薪資、最小值、最大值、平均值 - 使用groupby
        # print(data.groupby('sex')['salary'].aggregate(['sum', 'min', 'max', 'mean']))


        # data.groupby('sex')['salary'].aggregate([test])

        """
        groupby為分組操作類的function
        groupby主要操作為
        1. split: 先分群組
        2. apply: 套用的計算
        3. combine: 組合回去
        案例中是by sex欄位來分群組，分完群組後對salary欄位來進行操作
        :method count: 統計出現次數
        :method groups: 查看多少組別
        :method get_group: 尋找組別資料
        :method first: 群組的首個
        :method last: 群組的末個
        :method nth(n): 群組的第n個，從0開始

        aggregate為可將資料進行多個function的計算與統計的function，也可以用自己設定的function
        案例中是使用總和、最小值、最大值、平均值等function操作
        傳入自訂的function的內容可看見是篩選出來的Series
        """        
        ```


    21. **淺談SettingWithCopyWarning**
      + #### 範例
        ```python
        import pandas as pd

        data = pd.DataFrame({
            'name': ['Amy', 'John', 'David'],
            'salary': [3000, 5000, 8000],
            'heigh': [180, 400, 230]
        })

        # 將薪水小於7000的人，加薪2000

        # condition = data['salary'] < 7000  # 篩選

        # data['salary'][condition] += 2000  # 會發生SettingWithCopyWarning   
        # print(data) 

        # data.loc[condition, 'salary'] += 2000  # 不會發生SettingWithCopyWarning   
        # print(data)

        # low_salary = data[condition]    # 需加薪的資料
        # low_salary.loc[:, 'salary'] += 2000 # 會發生SettingWithCopyWarning 
        # print(low_salary)

        # low_salary = data[condition].copy()    # 需加薪的資料
        # low_salary.loc[:, 'salary'] += 2000 # 不會發生SettingWithCopyWarning 
        # print(low_salary)

        """
        SettingWithCopyWarning
        此警告是因為不確定是否真正修改到資料所造成的，幸運的話是會修改到，不幸的話可能沒改到，關鍵在於Views與Copies
        Views是原始對象的子集
        Copies則是副本，也就是全新的對象
        當作以下操作的時候，實際上對Pandas而言是作了兩個操作1.獲取項目 2.設定項目
        data[condition][key] += 2000 => data[condition]為獲取項目； [key] += 2000為設定項目
        data[condition].key += 2000 => data[condition]為獲取項目； .key += 2000為設定項目
        data[key].loc[condition] += 2000 => data[key]為獲取項目； .loc[condition] += 2000為設定項目
        通常我們執行操作完成後，副本將會被丟棄，重點在於，Pandas無法確定當獲取項目執行後，返回的是Views還是Copies
        如果是Views那設定項目後則會修改成功，如果返回的是Copies，抱歉，修改到副本，設定項目完成後，副本就丟棄了，修改不成功

        結論有兩個
        1. 如果是修改原來資料的部分訊息，先篩選出要改的部分，接著搭配loc[row, col]直接給予內容
        2. 如果是要修改原資料所篩選出來的副本內容的話，篩選出來的副本要先copy()，這樣才能確保真的修改到副本
        """        
        ```

    22. **將DataFrame中的list值分割成多個columns**
      + #### 範例
        ```python
        import pandas as pd
        df1 = pd.DataFrame({
            'key': [1, 2],
            'A': [['A1','A2','A3'], ['A4', 'A5']]
        })
        print(df1)
        df2 = pd.DataFrame(df1["A"].to_list(), columns=['A1', 'A2', 'A3'])
        print(df2)
        print('*'*100)
        print(pd.concat([df1, df2], axis=1, ignore_index=True)) # 合併

        """
        注意: 分割後的欄位一定要等於原list的數量，就是假如原value是A1~A3，那分割後的欄位要有3個，如果少於3個就會發生錯誤
        """        
        ```

    23. **樞紐分析表(數據透視表 pivot table)**
      + #### 定義
        是一種交互式的表，用來匯總其它表的數據。首先把源表分組（grouping），然後對各組內數據做匯總操作如排序、平均、累加、計數或字符串連接等。透視表用於數據處理，在數據可視化程序如電子表格或商業智能軟體中常見。 這種「旋轉」或者pivoting匯總表的概念得以命名。

      + #### 範例
        ```python
        import pandas as pd

        # 創建資料
        df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
                                  'two', 'one'],
                          'bar': ['A', 'B', 'C', 'A', 'B', 'C', 'A'],
                          'baz': [1, 2, 3, 4, 5, 6, 2],
                          'zoo': ['x', 'y', 'z', 'q', 'w', 't', 'a']})

        print(df)

        # print(df.pivot_table(index='foo', columns='bar', values='baz'))
        # print(df.pivot_table(index='foo', columns='bar', values='baz', aggfunc='max'))

        """
        pivot_table
        :index: column/Grouper/array/list of the previous，主要用來製作新索引的內容
        :columns: column/Grouper/array/list of the previous，用來製作新的columns
        :values: column to aggregate, optional，如果沒設定，將使用所有剩餘的列來製作，並且結果將具有分層索引的columns，主要製作內容用的
        :aggfunc: function, list of functions, dict, default numpy.mean，想套用的function
        主要是將df中，感興趣的多種欄位拉出來用對應關係的方式呈現，以利後續的統計
        """
        ```
    
    24. **分區間 cut**
        + #### 範例
        ```python 
        import pandas as pd

        x = [1, 34, 523, 56, 24, 6, 50]
        bins = [0, 10, 50, 50.01, 80, 100, 600]

        print(pd.cut(x, bins, right=False))

        """
        cut: 主要是用來將傳入的資料區分是哪個區間的
        :param x: array-like，欲分區間的資料
        :param bins: int, sequence of scalars, or IntervalIndex，設定的區間值
        :param right: bool, default True，右邊是否包括，預設是有，也就是如果區間是10,50,60，那50就會被分到10-50的區間
        :param labels: array or False, default None，區間的標籤名稱，可為每個區間做命名的動作
        """        
        ```
    
    25. **間隔N行做運算 Shift**
        + #### 範例
        ```python
        import pandas as pd
        import numpy as np

        df = pd.DataFrame({
            'col1': np.random.randint(1, 10, size=10),
            'col2': np.random.randint(10, 20, size=10),
            'col3': np.random.randint(20, 30, size=10)
        })

        print(df)

        # shift 主要是位移的功能
        # print('向下位移一個row\n', df.shift(periods=1, fill_value=0))
        # print('向右位移一個row\n', df.shift(periods=1, fill_value=0, axis=1))
        # print('向上位移一個row\n', df.shift(periods=-1, fill_value=0))
        # print('向左位移一個row\n', df.shift(periods=-1, fill_value=0, axis=1))

        # 應用: 奇數row - 偶數row
        # df1 = df.shift(periods=1, fill_value=0)
        # odd_even = df - df1
        # print(odd_even.loc[odd_even.index % 2 == 1])

        """
        shift: 位移
        :param periods: int，位移的數量，int為正數則為向下向右位移，若為負數則為向上向左位移
        :param fill_value: object, optional，位於後要填滿的東西
        """
        ```




+ ## 參考資料
  [參考網站](https://www.delftstack.com/zh-tw/howto/python-pandas/)
  [參考網站](https://pandas.pydata.org/docs/user_guide/index.html)
  [參考網站](https://iter01.com/585529.html)